{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import RegexTokenizer,VectorAssembler,Normalizer,StandardScaler,CountVectorizer,IDF \\\n",
    ",StringIndexer, MinMaxScaler\n",
    "from pyspark.sql.functions import udf,concat,lit\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Spark Session \n",
    "spark=SparkSession.builder.master('local').appName('Hyperparameter Tuning').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Body: string, Id: bigint, Tags: string, Title: string, oneTag: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the columns and the number of rows\n",
    "df=spark.read.json('../data/Train_onetag_small.json')\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing into 70% training and 30% testing\n",
    "train,test=df.randomSplit([0.9,0.1],seed=42)\n",
    "\n",
    "# For larger datasets this can be used to split data into 3 sets i.e. train/dev/test\n",
    "#train,rest=df.randomSplit([0.7,0.3],seed=42)\n",
    "#test,val=df.randomSplit([0.5,0,5],seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer=RegexTokenizer(inputCol='Body',outputCol='words',pattern=\"\\\\W\")\n",
    "cv=CountVectorizer(inputCol='words',outputCol='TF',vocabSize=1000)\n",
    "idf=IDF(inputCol='TF',outputCol='features')\n",
    "indexer=StringIndexer(inputCol='oneTag',outputCol='label')\n",
    "\n",
    "lr=LogisticRegression(maxIter=10,regParam=0.0,elasticNetParam=0)\n",
    "\n",
    "pipeline=Pipeline(stages=[regexTokenizer,cv,idf,indexer,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the underlining model\n",
    "pmodel=pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34690997076318175"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the result\n",
    "result=pmodel.transform(test)\n",
    "result.filter(result.prediction==result.label).count()/result.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we get a accuracy of 34.7% i.e. very less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid=ParamGridBuilder() \\\n",
    "            .addGrid(cv.vocabSize,[1000,5000])\\\n",
    "            .addGrid(lr.regParam,[0.0,0.1]).build()\n",
    "\n",
    "crossval=CrossValidator(estimator=pipeline,\n",
    "                       estimatorParamMaps=paramGrid,\n",
    "                       evaluator=MulticlassClassificationEvaluator(),\n",
    "                       numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel=crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30460039219970986,\n",
       " 0.23267537467422655,\n",
       " 0.36525309195440986,\n",
       " 0.28284587842893544]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.392378263937897"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=cvModel.transform(test)\n",
    "result.filter(result.prediction==result.label).count()/result.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can see that hyperparameter tuning improves the performance of our model. Even now the Accuracy is pretty low but is better than the prev case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
