{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim\n",
    "Understanding the Concept of pipeline by implementing Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import RegexTokenizer,IDF,CountVectorizer,StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Spark Session\n",
    "spark=SparkSession.builder.master('local').appName('Logistic Regression').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the json file into Spark df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Body: string, Id: bigint, Tags: string, Title: string, oneTag: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=spark.read.json('../data/Train_onetag_small.json')\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer=RegexTokenizer(inputCol='Body',outputCol='words',pattern=\"\\\\W\")\n",
    "cv=CountVectorizer(inputCol='words',outputCol='TF',vocabSize=1000)\n",
    "idf=IDF(inputCol='TF',outputCol='features')\n",
    "indexer=StringIndexer(inputCol='oneTag',outputCol='label')\n",
    "\n",
    "lr=LogisticRegression(maxIter=10,regParam=0.0,elasticNetParam=0)\n",
    "\n",
    "pipeline=Pipeline(stages=[regexTokenizer,cv,idf,indexer,lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the working of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plr_model=pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Body=\"<p>I'd like to check if an uploaded file is an image file (e.g png, jpg, jpeg, gif, bmp) or another file. The problem is that I'm using Uploadify to upload the files, which changes the mime type and gives a 'text/octal' or something as the mime type, no matter which file type you upload.</p>\\n\\n<p>Is there a way to check if the uploaded file is an image apart from checking the file extension using PHP?</p>\\n\", Id=1, Tags='php image-processing file-upload upload mime-types', Title='How to check if an uploaded file is an image without mime type?', oneTag='php', words=['p', 'i', 'd', 'like', 'to', 'check', 'if', 'an', 'uploaded', 'file', 'is', 'an', 'image', 'file', 'e', 'g', 'png', 'jpg', 'jpeg', 'gif', 'bmp', 'or', 'another', 'file', 'the', 'problem', 'is', 'that', 'i', 'm', 'using', 'uploadify', 'to', 'upload', 'the', 'files', 'which', 'changes', 'the', 'mime', 'type', 'and', 'gives', 'a', 'text', 'octal', 'or', 'something', 'as', 'the', 'mime', 'type', 'no', 'matter', 'which', 'file', 'type', 'you', 'upload', 'p', 'p', 'is', 'there', 'a', 'way', 'to', 'check', 'if', 'the', 'uploaded', 'file', 'is', 'an', 'image', 'apart', 'from', 'checking', 'the', 'file', 'extension', 'using', 'php', 'p'], TF=SparseVector(1000, {0: 4.0, 1: 6.0, 2: 2.0, 3: 3.0, 5: 2.0, 8: 4.0, 9: 1.0, 15: 1.0, 21: 2.0, 28: 1.0, 31: 1.0, 35: 3.0, 36: 1.0, 43: 2.0, 45: 2.0, 48: 1.0, 51: 1.0, 57: 6.0, 61: 2.0, 71: 1.0, 78: 1.0, 84: 3.0, 86: 1.0, 94: 1.0, 97: 1.0, 99: 1.0, 100: 1.0, 115: 1.0, 147: 2.0, 152: 1.0, 169: 1.0, 241: 1.0, 283: 1.0, 306: 1.0, 350: 2.0, 490: 1.0, 578: 1.0, 759: 1.0, 832: 2.0}), features=SparseVector(1000, {0: 0.0026, 1: 0.7515, 2: 0.1374, 3: 0.3184, 5: 0.3823, 8: 1.0754, 9: 0.3344, 15: 0.5899, 21: 1.8551, 28: 1.1263, 31: 1.1113, 35: 3.3134, 36: 1.2545, 43: 2.3741, 45: 2.3753, 48: 1.2254, 51: 1.1879, 57: 11.0264, 61: 2.8957, 71: 2.1945, 78: 1.6947, 84: 6.5898, 86: 1.6136, 94: 2.3569, 97: 1.8218, 99: 2.6292, 100: 1.9206, 115: 2.3592, 147: 5.4841, 152: 2.1116, 169: 2.6328, 241: 2.5745, 283: 3.2325, 306: 3.2668, 350: 6.2367, 490: 3.8893, 578: 3.6182, 759: 3.7771, 832: 8.8964}), label=3.0, rawPrediction=DenseVector([4.3561, 3.7158, 3.9252, 6.5266, 2.6863, 3.376, 2.1501, 3.0103, 3.0963, 0.947, 2.7247, 1.351, 2.6692, 1.0837, 0.9419, 2.3994, 1.3008, 2.114, 1.9185, 2.1695, 1.9607, 0.9716, 0.886, 1.4527, 0.9932, 1.9327, 1.6632, 1.3998, 1.2302, 1.1797, 1.3151, 1.0156, 1.2078, 0.7854, 0.9102, 1.3521, 0.6727, 1.4952, 1.8241, 1.1594, 0.946, 1.1233, 1.156, 1.239, 0.8427, 0.7222, 0.8731, 1.0679, 1.1605, 1.1331, 0.7814, 0.9909, 0.9034, 1.2087, 0.8857, 1.4443, 0.9715, 0.4755, 0.5806, 0.3858, 0.7771, 0.9584, 0.8699, 0.7622, 0.5561, 0.7465, 0.8109, 0.8665, 0.4109, 0.846, 1.058, 0.4833, 0.6517, 0.5909, 0.6856, 0.4652, 0.4635, 0.6983, 0.4035, 0.4452, 0.5067, 0.3834, 0.2736, 0.3747, 0.5158, 0.4308, 0.5393, 0.5154, 0.5042, 0.4782, 0.3438, 0.1493, 0.3453, 0.3128, 0.3071, 0.1383, 0.1796, 0.3869, 0.141, 0.2517, 0.2157, 0.2808, 0.2961, 0.4207, 0.0604, 0.0207, -0.1891, 0.5276, -0.0765, -0.0512, 0.0686, 0.1779, -0.1, 0.0045, -0.0632, -0.091, -0.0577, 0.2276, -0.126, -0.1439, -0.0548, 0.0039, -0.0412, 0.008, 0.033, 0.1884, -0.1182, 0.2282, -0.1017, -0.0642, -0.2003, -0.0751, -0.159, 0.1302, -0.2261, 0.1558, -0.0425, -0.1892, -0.1318, -0.1542, -0.2054, -0.1944, 0.0133, -0.3427, -0.2235, -0.1651, -0.2, -0.1063, -0.3925, -0.2345, -0.2734, -0.1548, -0.2451, -0.4066, -0.2937, -0.3587, -0.3354, -0.2733, -0.308, -0.2021, -0.3738, -0.4513, -0.3034, -0.4439, -0.3727, -0.4228, -0.4232, -0.3714, -0.3049, -0.4013, -0.4104, -0.5534, -0.35, -0.4141, -0.4, -0.4162, -0.3763, -0.3242, -0.4028, -0.4575, -0.4279, -0.0313, -0.5772, -0.4781, -0.3972, -0.4862, -0.5334, -0.6531, -0.2726, -0.6126, -0.5029, -0.5182, -0.6167, -0.6075, -0.617, -0.6298, -0.6246, -0.5706, -0.5923, -0.6146, -0.4167, -0.7126, -0.6724, -0.5153, -0.6442, -0.5438, -0.5776, -0.6957, -0.5837, -0.6565, -0.75, -0.7571, -0.6838, -0.6246, -0.7499, -0.6193, -0.6875, -0.6051, -0.6539, -0.7522, -0.7032, -0.7013, -0.7024, -0.7582, -0.616, -0.8041, -0.8194, -0.7518, -0.7783, -0.796, -0.9197, -0.8047, -0.8978, -0.7639, -0.8221, -0.7903, -0.8267, -0.8331, -0.9169, -0.7712, -0.9191, -0.7988, -0.8821, -0.8377, -0.9422, -0.815, -0.9167, -0.8556, -0.9306, -0.9078, -0.895, -0.95, -0.9352, -0.9628, -0.9648, -0.8278, -1.0541, -0.9911, -1.0197, -1.0225, -0.9933, -0.9506, -0.8358, -0.8798, -1.0145, -0.9673, -1.0825, -1.0587, -1.1202, -1.1145, -1.1208, -0.9899, -1.0284, -1.0947, -1.1578, -1.1414, -1.0474, -1.1412, -1.0983, -1.1428, -1.1113, -1.1368, -1.0908, -1.1877, -1.0879, -1.1321, -1.1498, -1.1429, -1.192, -1.2172, -1.2251, -1.2287, -1.2379, -1.2352, -1.3865, -1.4595, -1.386, -1.449, -1.5266, -1.4852, -1.5841]), probability=DenseVector([0.0578, 0.0305, 0.0376, 0.5063, 0.0109, 0.0217, 0.0064, 0.015, 0.0164, 0.0019, 0.0113, 0.0029, 0.0107, 0.0022, 0.0019, 0.0082, 0.0027, 0.0061, 0.005, 0.0065, 0.0053, 0.002, 0.0018, 0.0032, 0.002, 0.0051, 0.0039, 0.003, 0.0025, 0.0024, 0.0028, 0.002, 0.0025, 0.0016, 0.0018, 0.0029, 0.0015, 0.0033, 0.0046, 0.0024, 0.0019, 0.0023, 0.0024, 0.0026, 0.0017, 0.0015, 0.0018, 0.0022, 0.0024, 0.0023, 0.0016, 0.002, 0.0018, 0.0025, 0.0018, 0.0031, 0.002, 0.0012, 0.0013, 0.0011, 0.0016, 0.0019, 0.0018, 0.0016, 0.0013, 0.0016, 0.0017, 0.0018, 0.0011, 0.0017, 0.0021, 0.0012, 0.0014, 0.0013, 0.0015, 0.0012, 0.0012, 0.0015, 0.0011, 0.0012, 0.0012, 0.0011, 0.001, 0.0011, 0.0012, 0.0011, 0.0013, 0.0012, 0.0012, 0.0012, 0.001, 0.0009, 0.001, 0.001, 0.001, 0.0009, 0.0009, 0.0011, 0.0009, 0.001, 0.0009, 0.001, 0.001, 0.0011, 0.0008, 0.0008, 0.0006, 0.0013, 0.0007, 0.0007, 0.0008, 0.0009, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0009, 0.0007, 0.0006, 0.0007, 0.0007, 0.0007, 0.0007, 0.0008, 0.0009, 0.0007, 0.0009, 0.0007, 0.0007, 0.0006, 0.0007, 0.0006, 0.0008, 0.0006, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0008, 0.0005, 0.0006, 0.0006, 0.0006, 0.0007, 0.0005, 0.0006, 0.0006, 0.0006, 0.0006, 0.0005, 0.0006, 0.0005, 0.0005, 0.0006, 0.0005, 0.0006, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0004, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0007, 0.0004, 0.0005, 0.0005, 0.0005, 0.0004, 0.0004, 0.0006, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0005, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0003, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0003, 0.0004, 0.0004, 0.0004, 0.0003, 0.0004, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002]), prediction=3.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=plr_model.transform(df)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36740"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Count of correctly classified labels\n",
    "df2.filter(df2.label==df2.prediction).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better performance we can increase the Vocab size of our TFIDF features. Also we can improve the performance by implementing HyperParameter Tuning. Check the other ipynb for this. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
